# ðŸš€ Hevo Data Assessment â€“ End-to-End Data Pipeline (PostgreSQL â†’ Hevo â†’ Snowflake)

This project demonstrates the setup of a **complete data pipeline** using **PostgreSQL (Neon)**, **Hevo Data**, and **Snowflake**.  
It covers every step from environment setup, data ingestion, transformation (via Python), and validation in the destination warehouse.

---

## ðŸ“– Overview

The goal of this project was to:

- âœ… Set up a **Snowflake trial account** and connect it with a **Hevo partner account**
- âœ… Establish a working **PostgreSQL** environment
- âœ… Ingest data from CSV files into PostgreSQL
- âœ… Connect PostgreSQL to Hevo as a source
- âœ… Apply transformations using **Python** in Hevo
- âœ… Load transformed data into **Snowflake**
- âœ… Validate the final results using SQL queries

---

## ðŸ Step 1: Destination Setup (Snowflake Partner Connect)

### 1ï¸âƒ£ Snowflake Trial Account Creation
- Created a Snowflake trial account using Gmail.
- Logged in as admin.

### 2ï¸âƒ£ Hevo Partner Account Setup
- Inside Snowflake, navigated to **Admin â†’ Partner Connect**.
- Selected **Hevo Data** and authorized connection.
- Hevo workspace auto-provisioned.

âœ… *Hevo connected to Snowflake successfully.*

---

## ðŸ³ Step 2: Initial Setup Attempt with Docker (and Why It Was Replaced)

### 1ï¸âƒ£ Docker Setup
- Installed Docker Desktop and attempted to create a local PostgreSQL container.
- Verified installation using:
  ```bash
  docker version
  ```
  âœ… Command worked successfully.

### 2ï¸âƒ£ Issue Encountered
- Launching the container threw repeated **500 API errors**.

### 3ï¸âƒ£ Decision
- Switched to **Neon.tech**, a managed cloud PostgreSQL service with:
  - Free tier  
  - GUI  
  - Logical replication support

---

## ðŸ§± Step 3: PostgreSQL Setup in Neon

- Signed up at [Neon Console](https://console.neon.tech).
- Created project and database **`neondb`**.
- Default role: `neondb_owner`.

âœ… *Connection successful.*

### Connection via pgAdmin
Created a new server named **neondb** using these credentials:

| Parameter | Value |
|------------|--------|
| Hostname | `ep-delicate-math-adkswflv-pooler.c-2.us-east-1.aws.neon.tech` |
| Database | `neondb` |
| User | `neondb_owner` |
| Password | `********` |

âœ… *pgAdmin connected successfully.*

---

## ðŸ§® Step 4: Table Creation and Data Import under pgAdmin

### 1ï¸âƒ£ Table Creation
```sql
CREATE TABLE customers (
    id SERIAL PRIMARY KEY,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    email VARCHAR(100),
    address JSON
);

CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    customer_id INT,
    status VARCHAR(50),
    total_amount NUMERIC(10,2)
);

CREATE TABLE feedback (
    order_id INT PRIMARY KEY,
    rating INT,
    comment TEXT
);
```

### 2ï¸âƒ£ Data Import
Downloaded CSV files from:  
ðŸ“‚ [Hevo Assessment CSV Repo](https://github.com/muskan-kesharwani-hevo/hevo-assessment-csv)

- `customers.csv`
- `orders.csv`
- `feedback.csv`

Imported using pgAdminâ€™s **Import/Export Data** tool.

---

### âš ï¸ Issue 1: Invalid JSON Format
**Error:**  
`invalid input syntax for type json`

**Root Cause:**  
`address` column values not enclosed in double quotes.

**Fix:**  
Converted column type from `JSON` â†’ `TEXT`
```sql
ALTER TABLE customers ALTER COLUMN address TYPE TEXT USING address::TEXT;
```
âœ… *Re-imported successfully.*

---

### âš ï¸ Issue 2: Duplicate Key Violation
**Error:**  
```
ERROR: duplicate key value violates unique constraint "feedback_order_id_key"
DETAIL: Key (order_id)=(1121) already exists.
```

**Root Cause:**  
133 duplicate `order_id` values in `feedback.csv`.

**Fix using Python (Pandas):**
```python
import pandas as pd
df = pd.read_csv('feedback.csv')
df = df.drop_duplicates(subset='order_id', keep='first')
df.to_csv('feedback_clean.csv', index=False)
```
âœ… *Re-imported `feedback_clean.csv` successfully.*

---

## ðŸ”— Step 5: Connect PostgreSQL to Hevo

### 1ï¸âƒ£ Pipeline Setup
- Source: PostgreSQL (Neon)
- Destination: Snowflake

### 2ï¸âƒ£ Connection Configuration
| Parameter | Value |
|------------|--------|
| Host | `ep-delicate-math-adkswflv-pooler.c-2.us-east-1.aws.neon.tech` |
| Database | `neondb` |
| User | `neondb_owner` |
| Password | `********` |

### 3ï¸âƒ£ Error Encountered
Hevo error:
> Unable to use logical replication. wal_level must be set to 'logical'

### 4ï¸âƒ£ Fix
- Logged in to **Neon â†’ Settings â†’ Enable Logical Replication**
- Verified using:
  ```sql
  SHOW wal_level;
  ```
  Output: `logical`

âœ… *Reconnected successfully.*

---

## âš™ï¸ Step 6: Hevo Pipeline Configuration

| Setting | Value |
|----------|--------|
| Destination Table Prefix | *(Blank)* |
| Auto Mapping | Enabled |
| Ingestion Schedule | Every 30 minutes |

âœ… *Tables from PostgreSQL successfully appeared in Hevo.*

---

## ðŸ§  Step 7: Data Transformation in Hevo (Python Script)

### Transformation Goals
1. Derive **username** from email in `customers`
2. Create new derived table **order_events** from `orders`
3. Pass other tables unchanged

### Python Script
```python
import datetime

def transform(event):
    table_name = event.get('__table_name')
    if not table_name:
        return event, None

    # 1ï¸âƒ£ Add username for customers
    if table_name == 'customers':
        email = event.get('email')
        if email and '@' in email:
            event['username'] = email.split('@')[0]
        return event, table_name

    # 2ï¸âƒ£ Generate order_events for orders
    elif table_name == 'orders':
        status_map = {
            'delivered': 'order_delivered',
            'placed': 'order_placed',
            'shipped': 'order_shipped',
            'cancelled': 'order_cancelled'
        }
        status = event.get('status')
        output_records = [(event, table_name)]

        if status in status_map:
            new_event_record = {
                'order_id': event.get('id'),
                'customer_id': event.get('customer_id'),
                'event_type': status_map[status],
                'event_timestamp': datetime.datetime.now().isoformat()
            }
            output_records.append((new_event_record, 'order_events'))
        return output_records

    # 3ï¸âƒ£ Pass feedback and other tables
    return event, table_name
```

âœ… *Transformation deployed successfully.*

---

## â„ï¸ Step 8: Load and Validate in Snowflake

**Database:** `PC_HEVODATA_DB`  
**Schema:** `PUBLIC`

### SQL Operations
```sql
ALTER TABLE PC_HEVODATA_DB.PUBLIC.CUSTOMERS
ADD COLUMN USERNAME VARCHAR;

UPDATE PC_HEVODATA_DB.PUBLIC.CUSTOMERS
SET USERNAME = SPLIT_PART(EMAIL, '@', 1);
```

---

### âœ… Validation Queries

**Validation A â€” Order Events**
```sql
SELECT EVENT_TYPE, COUNT(*)
FROM PC_HEVODATA_DB.PUBLIC.ORDER_EVENTS
GROUP BY EVENT_TYPE;
```

**Validation B â€” Username Field**
```sql
SELECT EMAIL, USERNAME, FIRST_NAME
FROM PC_HEVODATA_DB.PUBLIC.CUSTOMERS
WHERE USERNAME IS NOT NULL
LIMIT 10;
```

âœ… *All validation checks passed successfully.*

---

## ðŸ’¡ Issues Encountered & Design Choices

| Category | Decision / Assumption |
|-----------|------------------------|
| Address Field | Converted JSON â†’ TEXT for simplicity |
| Order Status Type | Used VARCHAR instead of ENUM for flexibility |
| Duplicate Handling | Removed duplicates at source using Python |
| Transformation Type | Used Python for precise control |
| Ingestion Frequency | 30-minute schedule for steady sync |

---

## ðŸ“ Repository Structure

```
ðŸ“¦ hevo-data-assessment
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â”œâ”€â”€ validation_queries.sql
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â”œâ”€â”€ feedback_clean.csv
â”‚
â”œâ”€â”€ transform/
â”‚   â””â”€â”€ transform_script.py
```

---

## ðŸ§© Summary

âœ… Attempted PostgreSQL via Docker (failed due to 500 API error)  
âœ… Switched to **Neon PostgreSQL** (successful)  
âœ… Created & populated tables  
âœ… Connected **PostgreSQL â†’ Hevo** with logical replication  
âœ… Applied **Python transformations**  
âœ… Synced data to **Snowflake**  
âœ… Verified transformations and data integrity  

---

### ðŸ·ï¸ About

> **Author:** Kashish Pal  
> **Project:** Hevo Data Assessment I  
> **Technologies:** PostgreSQL (Neon), Hevo Data, Snowflake, Python, SQL  

---

ðŸ“˜ *This repository demonstrates an end-to-end ELT workflow leveraging cloud-native data engineering tools for modern analytics pipelines.*
